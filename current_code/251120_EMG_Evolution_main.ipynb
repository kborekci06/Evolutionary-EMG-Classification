{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Computation for Evolving Neural Network EMG Classifier Structure and Weights\n",
    "In this project, the goal is to improve the structure and weights of a neural network that classifies EMG signals, and compare the genetic solutions to standard classifiers.\n",
    "\n",
    "Controls:\n",
    "- Random Forest Classifier\n",
    "- Neural Network (Backpropagation)\n",
    "\n",
    "Evolutionary Models:\n",
    "- NEAT (NeuroEvolution of Augmenting Topologies)\n",
    "- HyperNEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Custom library\n",
    "from emg_evo_lib_kb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset root\n",
    "root_path = Path(\"/Users/kaanborekci/Desktop/CS496/Code/Self-Project-Evolutionary-Computation/EMG-Project/UC-Irvine-Set/EMG_data_for_gestures-master\")\n",
    "\n",
    "# Column names in each raw file\n",
    "emg_column_names = [\"Time\"] + [f\"ch{i}\" for i in range(1, 9)] + [\"Class\"]\n",
    "\n",
    "# Gesture classes we care about (ignore 0 = unmarked)\n",
    "gesture_classes = [1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73 EMG files under /Users/kaanborekci/Desktop/CS496/Code/Self-Project-Evolutionary-Computation/EMG-Project/UC-Irvine-Set/EMG_data_for_gestures-master\n",
      "[1/73] 1_raw_data_13-12_22.03.16.txt: 12 gesture segments\n",
      "[2/73] 2_raw_data_13-13_22.03.16.txt: 12 gesture segments\n",
      "[3/73] 1_raw_data_14-19_22.03.16.txt: 12 gesture segments\n",
      "[4/73] 2_raw_data_14-21_22.03.16.txt: 12 gesture segments\n",
      "[5/73] 1_raw_data_09-32_11.04.16.txt: 12 gesture segments\n",
      "[6/73] 2_raw_data_09-34_11.04.16.txt: 12 gesture segments\n",
      "[7/73] 1_raw_data_18-02_24.04.16.txt: 12 gesture segments\n",
      "[8/73] 2_raw_data_18-03_24.04.16.txt: 12 gesture segments\n",
      "[9/73] 1_raw_data_10-28_30.03.16.txt: 12 gesture segments\n",
      "[10/73] 2_raw_data_10-29_30.03.16.txt: 12 gesture segments\n",
      "[11/73] 1_raw_data_10-38_11.04.16.txt: 12 gesture segments\n",
      "[12/73] 2_raw_data_10-40_11.04.16.txt: 12 gesture segments\n",
      "[13/73] 1_raw_data_18-48_22.03.16.txt: 12 gesture segments\n",
      "[14/73] 2_raw_data_18-50_22.03.16.txt: 12 gesture segments\n",
      "[15/73] 1_raw_data_12-14_23.03.16.txt: 12 gesture segments\n",
      "[16/73] 2_raw_data_12-16_23.03.16.txt: 12 gesture segments\n",
      "[17/73] 1_raw_data_12-41_23.03.16.txt: 12 gesture segments\n",
      "[18/73] 2_raw_data_12-43_23.03.16.txt: 12 gesture segments\n",
      "[19/73] 1_raw_data_11-08_21.03.16.txt: 12 gesture segments\n",
      "[20/73] 2_raw_data_11-10_21.03.16.txt: 12 gesture segments\n",
      "[21/73] 1_raw_data_13-11_18.03.16.txt: 14 gesture segments\n",
      "[22/73] 2_raw_data_13-13_18.03.16.txt: 14 gesture segments\n",
      "[23/73] 1_raw_data_11-35_28.03.16.txt: 12 gesture segments\n",
      "[24/73] 2_raw_data_11-36_28.03.16.txt: 12 gesture segments\n",
      "[25/73] 1_raw_data_13-26_21.03.16.txt: 12 gesture segments\n",
      "[26/73] 2_raw_data_13-29_21.03.16.txt: 12 gesture segments\n",
      "[27/73] 1_raw_data_09-50_15.04.16.txt: 12 gesture segments\n",
      "[28/73] 2_raw_data_09-51_15.04.16.txt: 12 gesture segments\n",
      "[29/73] 1_raw_data_08-49_13.04.16.txt: 12 gesture segments\n",
      "[30/73] 2_raw_data_08-51_13.04.16.txt: 12 gesture segments\n",
      "[31/73] 1_raw_data_12-12_25.04.16.txt: 12 gesture segments\n",
      "[32/73] 2_raw_data_12-14_25.04.16.txt: 12 gesture segments\n",
      "[33/73] 1_raw_data_11-19_23.03.16.txt: 12 gesture segments\n",
      "[34/73] 2_raw_data_11-20_23.03.16.txt: 12 gesture segments\n",
      "[35/73] 1_raw_data_12-35_21.03.16.txt: 12 gesture segments\n",
      "[36/73] 2_raw_data_12-37_21.03.16.txt: 12 gesture segments\n",
      "[37/73] 1_raw_data_12-10_26.04.16.txt: 12 gesture segments\n",
      "[38/73] 2_raw_data_12-11_26.04.16.txt: 12 gesture segments\n",
      "[39/73] 1_raw_data_11-41_22.03.16.txt: 12 gesture segments\n",
      "[40/73] 2_raw_data_11-43_22.03.16.txt: 12 gesture segments\n",
      "[41/73] 1_raw_data_20-28_24.04.16.txt: 12 gesture segments\n",
      "[42/73] 2_raw_data_20-30_24.04.16.txt: 12 gesture segments\n",
      "[43/73] 1_raw_data_12-37_28.03.16.txt: 12 gesture segments\n",
      "[44/73] 2_raw_data_12-39_28.03.16.txt: 12 gesture segments\n",
      "[45/73] 1_raw_data_13-18_05.04.16.txt: 12 gesture segments\n",
      "[46/73] 2_raw_data_13-19_05.04.16.txt: 12 gesture segments\n",
      "[47/73] 1_raw_data_10-16_12.04.16.txt: 12 gesture segments\n",
      "[48/73] 2_raw_data_10-17_12.04.16.txt: 12 gesture segments\n",
      "[49/73] 1_raw_data_14-51_24.04.16.txt: 12 gesture segments\n",
      "[50/73] 2_raw_data_14-53_24.04.16.txt: 12 gesture segments\n",
      "[51/73] 1_raw_data_10-22_29.03.16.txt: 12 gesture segments\n",
      "[52/73] 2_raw_data_10-23_29.03.16.txt: 12 gesture segments\n",
      "[53/73] 1_raw_data_12-19_06.04.16.txt: 12 gesture segments\n",
      "[54/73] 2_raw_data_12-20_06.04.16.txt: 12 gesture segments\n",
      "[55/73] 1_raw_data_12-10_15.04.16.txt: 12 gesture segments\n",
      "[56/73] 2_raw_data_12-11_15.04.16.txt: 12 gesture segments\n",
      "[57/73] 1_raw_data_10-17_15.04.16.txt: 12 gesture segments\n",
      "[58/73] 2_raw_data_10-18_15.04.16.txt: 12 gesture segments\n",
      "[59/73] 1_raw_data_09-49_21.03.16.txt: 14 gesture segments\n",
      "[60/73] 2_raw_data_09-50_21.03.16.txt: 14 gesture segments\n",
      "[61/73] 1_raw_data_11-15_11.04.16.txt: 12 gesture segments\n",
      "[62/73] 2_raw_data_11-16_11.04.16.txt: 12 gesture segments\n",
      "[63/73] 1_raw_data_12-04_27.04.16.txt: 12 gesture segments\n",
      "[64/73] 2_raw_data_12-06_27.04.16.txt: 12 gesture segments\n",
      "[65/73] 1_raw_data_09-49_12.04.16.txt: 12 gesture segments\n",
      "[66/73] 2_raw_data_09-50_12.04.16.txt: 12 gesture segments\n",
      "[67/73] 1_raw_data_10-51_07.04.16.txt: 12 gesture segments\n",
      "[68/73] 2_raw_data_10-53_07.04.16.txt: 12 gesture segments\n",
      "[69/73] 1_raw_data_10-03_13.04.16.txt: 12 gesture segments\n",
      "[70/73] 2_raw_data_10-05_13.04.16.txt: 12 gesture segments\n",
      "[71/73] 1_raw_data_13-03_15.04.16.txt: 12 gesture segments\n",
      "[72/73] 2_raw_data_13-04_15.04.16.txt: 12 gesture segments\n",
      "[73/73] README.txt: 0 gesture segments\n",
      "Total segments: 872\n",
      "Feature matrix shape: (872, 64)\n",
      "X shape: (872, 64)\n",
      "Example feature vector length: 64\n",
      "Example feature vector: [1.57191666e-05 1.19338061e-05 3.03000000e-03 2.70000000e+01\n",
      " 1.80000000e+01 1.55693174e-10 2.05997198e+01 0.00000000e+00\n",
      " 2.45787200e-05 1.88226950e-05 5.26000000e-03 6.10000000e+01\n",
      " 1.50000000e+01 4.99522962e-10 2.95944050e+01 1.08747045e+01\n",
      " 2.77884613e-05 2.16359338e-05 7.03000000e-03 8.80000000e+01\n",
      " 2.00000000e+01 6.81160818e-10 3.89252940e+01 1.70212766e+01\n",
      " 2.01565973e-05 1.56548463e-05 4.40000000e-03 6.20000000e+01\n",
      " 1.70000000e+01 3.11881696e-10 2.84813214e+01 8.03782506e+00\n",
      " 1.57911906e-05 1.24822695e-05 3.00000000e-03 3.70000000e+01\n",
      " 1.50000000e+01 1.37592319e-10 1.79862788e+01 0.00000000e+00\n",
      " 1.42238105e-05 1.07281324e-05 2.50000000e-03 2.50000000e+01\n",
      " 1.50000000e+01 1.18440633e-10 1.82574677e+01 0.00000000e+00\n",
      " 1.35059745e-05 1.03924350e-05 2.76000000e-03 3.20000000e+01\n",
      " 1.50000000e+01 1.08524521e-10 2.20003025e+01 0.00000000e+00\n",
      " 1.41855319e-05 1.09503546e-05 2.85000000e-03 3.30000000e+01\n",
      " 1.30000000e+01 1.20356924e-10 2.21596719e+01 0.00000000e+00]\n",
      "Example label: 1\n",
      "Example meta: {'file_path': '/Users/kaanborekci/Desktop/CS496/Code/Self-Project-Evolutionary-Computation/EMG-Project/UC-Irvine-Set/EMG_data_for_gestures-master/01/1_raw_data_13-12_22.03.16.txt', 'subject_id': '01', 'segment_index': 0, 'label': 1, 'num_samples': 2115}\n"
     ]
    }
   ],
   "source": [
    "X, y, meta = build_feature_dataset(root_path, emg_column_names, gesture_classes)\n",
    "print(\"X shape:\", X.shape)\n",
    "if len(X) > 0:\n",
    "    print(\"Example feature vector length:\", len(X[0]))\n",
    "    print(\"Example feature vector:\", X[0])\n",
    "    print(\"Example label:\", y[0])\n",
    "    print(\"Example meta:\", meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3,\n",
       "       4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5,\n",
       "       6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2,\n",
       "       3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6,\n",
       "       1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4,\n",
       "       5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73 EMG files under /Users/kaanborekci/Desktop/CS496/Code/Self-Project-Evolutionary-Computation/EMG-Project/UC-Irvine-Set/EMG_data_for_gestures-master\n",
      "[1/73] 1_raw_data_13-12_22.03.16.txt: 12 gesture segments\n",
      "[2/73] 2_raw_data_13-13_22.03.16.txt: 12 gesture segments\n",
      "[3/73] 1_raw_data_14-19_22.03.16.txt: 12 gesture segments\n",
      "[4/73] 2_raw_data_14-21_22.03.16.txt: 12 gesture segments\n",
      "[5/73] 1_raw_data_09-32_11.04.16.txt: 12 gesture segments\n",
      "[6/73] 2_raw_data_09-34_11.04.16.txt: 12 gesture segments\n",
      "[7/73] 1_raw_data_18-02_24.04.16.txt: 12 gesture segments\n",
      "[8/73] 2_raw_data_18-03_24.04.16.txt: 12 gesture segments\n",
      "[9/73] 1_raw_data_10-28_30.03.16.txt: 12 gesture segments\n",
      "[10/73] 2_raw_data_10-29_30.03.16.txt: 12 gesture segments\n",
      "[11/73] 1_raw_data_10-38_11.04.16.txt: 12 gesture segments\n",
      "[12/73] 2_raw_data_10-40_11.04.16.txt: 12 gesture segments\n",
      "[13/73] 1_raw_data_18-48_22.03.16.txt: 12 gesture segments\n",
      "[14/73] 2_raw_data_18-50_22.03.16.txt: 12 gesture segments\n",
      "[15/73] 1_raw_data_12-14_23.03.16.txt: 12 gesture segments\n",
      "[16/73] 2_raw_data_12-16_23.03.16.txt: 12 gesture segments\n",
      "[17/73] 1_raw_data_12-41_23.03.16.txt: 12 gesture segments\n",
      "[18/73] 2_raw_data_12-43_23.03.16.txt: 12 gesture segments\n",
      "[19/73] 1_raw_data_11-08_21.03.16.txt: 12 gesture segments\n",
      "[20/73] 2_raw_data_11-10_21.03.16.txt: 12 gesture segments\n",
      "[21/73] 1_raw_data_13-11_18.03.16.txt: 14 gesture segments\n",
      "[22/73] 2_raw_data_13-13_18.03.16.txt: 14 gesture segments\n",
      "[23/73] 1_raw_data_11-35_28.03.16.txt: 12 gesture segments\n",
      "[24/73] 2_raw_data_11-36_28.03.16.txt: 12 gesture segments\n",
      "[25/73] 1_raw_data_13-26_21.03.16.txt: 12 gesture segments\n",
      "[26/73] 2_raw_data_13-29_21.03.16.txt: 12 gesture segments\n",
      "[27/73] 1_raw_data_09-50_15.04.16.txt: 12 gesture segments\n",
      "[28/73] 2_raw_data_09-51_15.04.16.txt: 12 gesture segments\n",
      "[29/73] 1_raw_data_08-49_13.04.16.txt: 12 gesture segments\n",
      "[30/73] 2_raw_data_08-51_13.04.16.txt: 12 gesture segments\n",
      "[31/73] 1_raw_data_12-12_25.04.16.txt: 12 gesture segments\n",
      "[32/73] 2_raw_data_12-14_25.04.16.txt: 12 gesture segments\n",
      "[33/73] 1_raw_data_11-19_23.03.16.txt: 12 gesture segments\n",
      "[34/73] 2_raw_data_11-20_23.03.16.txt: 12 gesture segments\n",
      "[35/73] 1_raw_data_12-35_21.03.16.txt: 12 gesture segments\n",
      "[36/73] 2_raw_data_12-37_21.03.16.txt: 12 gesture segments\n",
      "[37/73] 1_raw_data_12-10_26.04.16.txt: 12 gesture segments\n",
      "[38/73] 2_raw_data_12-11_26.04.16.txt: 12 gesture segments\n",
      "[39/73] 1_raw_data_11-41_22.03.16.txt: 12 gesture segments\n",
      "[40/73] 2_raw_data_11-43_22.03.16.txt: 12 gesture segments\n",
      "[41/73] 1_raw_data_20-28_24.04.16.txt: 12 gesture segments\n",
      "[42/73] 2_raw_data_20-30_24.04.16.txt: 12 gesture segments\n",
      "[43/73] 1_raw_data_12-37_28.03.16.txt: 12 gesture segments\n",
      "[44/73] 2_raw_data_12-39_28.03.16.txt: 12 gesture segments\n",
      "[45/73] 1_raw_data_13-18_05.04.16.txt: 12 gesture segments\n",
      "[46/73] 2_raw_data_13-19_05.04.16.txt: 12 gesture segments\n",
      "[47/73] 1_raw_data_10-16_12.04.16.txt: 12 gesture segments\n",
      "[48/73] 2_raw_data_10-17_12.04.16.txt: 12 gesture segments\n",
      "[49/73] 1_raw_data_14-51_24.04.16.txt: 12 gesture segments\n",
      "[50/73] 2_raw_data_14-53_24.04.16.txt: 12 gesture segments\n",
      "[51/73] 1_raw_data_10-22_29.03.16.txt: 12 gesture segments\n",
      "[52/73] 2_raw_data_10-23_29.03.16.txt: 12 gesture segments\n",
      "[53/73] 1_raw_data_12-19_06.04.16.txt: 12 gesture segments\n",
      "[54/73] 2_raw_data_12-20_06.04.16.txt: 12 gesture segments\n",
      "[55/73] 1_raw_data_12-10_15.04.16.txt: 12 gesture segments\n",
      "[56/73] 2_raw_data_12-11_15.04.16.txt: 12 gesture segments\n",
      "[57/73] 1_raw_data_10-17_15.04.16.txt: 12 gesture segments\n",
      "[58/73] 2_raw_data_10-18_15.04.16.txt: 12 gesture segments\n",
      "[59/73] 1_raw_data_09-49_21.03.16.txt: 14 gesture segments\n",
      "[60/73] 2_raw_data_09-50_21.03.16.txt: 14 gesture segments\n",
      "[61/73] 1_raw_data_11-15_11.04.16.txt: 12 gesture segments\n",
      "[62/73] 2_raw_data_11-16_11.04.16.txt: 12 gesture segments\n",
      "[63/73] 1_raw_data_12-04_27.04.16.txt: 12 gesture segments\n",
      "[64/73] 2_raw_data_12-06_27.04.16.txt: 12 gesture segments\n",
      "[65/73] 1_raw_data_09-49_12.04.16.txt: 12 gesture segments\n",
      "[66/73] 2_raw_data_09-50_12.04.16.txt: 12 gesture segments\n",
      "[67/73] 1_raw_data_10-51_07.04.16.txt: 12 gesture segments\n",
      "[68/73] 2_raw_data_10-53_07.04.16.txt: 12 gesture segments\n",
      "[69/73] 1_raw_data_10-03_13.04.16.txt: 12 gesture segments\n",
      "[70/73] 2_raw_data_10-05_13.04.16.txt: 12 gesture segments\n",
      "[71/73] 1_raw_data_13-03_15.04.16.txt: 12 gesture segments\n",
      "[72/73] 2_raw_data_13-04_15.04.16.txt: 12 gesture segments\n",
      "[73/73] README.txt: 0 gesture segments\n",
      "Total segments: 872\n",
      "Feature matrix shape: (872, 64)\n",
      "\n",
      "Unique labels in y: [1 2 3 4 5 6 7]\n",
      "Total samples: 872\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memg_column_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgesture_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CS496/Code/Self-Project-Evolutionary-Computation/EMG-Project/Evolutionary-EMG-Classification/src/emg_evo_lib_kb/control_nn.py:148\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(root, emg_column_names, valid_classes, hidden_layers)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03mFull training + evaluation pipeline for the control neural network.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m    - Print metrics and plot confusion matrix on test set\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# 1. Load and split data\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m X_train, X_val, X_test, y_train, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_and_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memg_column_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInput feature dimension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CS496/Code/Self-Project-Evolutionary-Computation/EMG-Project/Evolutionary-EMG-Classification/src/emg_evo_lib_kb/control_nn.py:54\u001b[0m, in \u001b[0;36mload_data_and_split\u001b[0;34m(root, emg_column_names, valid_classes, test_size, val_size, random_state)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Then split temp into val + test\u001b[39;00m\n\u001b[1;32m     53\u001b[0m val_ratio \u001b[38;5;241m=\u001b[39m val_size \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m test_size)  \u001b[38;5;66;03m# fraction of X_temp to use as val\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m X_val, X_test, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_temp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_temp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_temp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSplit sizes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/openmmlab/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/envs/openmmlab/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2670\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2666\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2668\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2670\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2673\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2674\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2675\u001b[0m     )\n\u001b[1;32m   2676\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/openmmlab/lib/python3.8/site-packages/sklearn/model_selection/_split.py:1746\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1717\u001b[0m \n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1746\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/miniconda/envs/openmmlab/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2147\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2145\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 2147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2152\u001b[0m     )\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[1;32m   2155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[1;32m   2158\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "train_and_evaluate(root_path, emg_column_names, gesture_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
